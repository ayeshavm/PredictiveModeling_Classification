{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Petfinder.my Adoption Prediction\n",
    "How cute is that doggy in the shelter?\n",
    "\n",
    "## Competition Description:\n",
    "\n",
    "Millions of stray animals suffer on the streets or are euthanized in shelters every day around the world. If homes can be found for them, many precious lives can be saved — and more happy families created.\n",
    "\n",
    "PetFinder.my has been Malaysia’s leading animal welfare platform since 2008, with a database of more than 150,000 animals. PetFinder collaborates closely with animal lovers, media, corporations, and global organizations to improve animal welfare.\n",
    "\n",
    "Animal adoption rates are strongly correlated to the metadata associated with their online profiles, such as descriptive text and photo characteristics. As one example, PetFinder is currently experimenting with a simple AI tool called the Cuteness Meter, which ranks how cute a pet is based on qualities present in their photos.\n",
    "\n",
    "In this competition you will be developing algorithms to predict the adoptability of pets - specifically, how quickly is a pet adopted? If successful, they will be adapted into AI tools that will guide shelters and rescuers around the world on improving their pet profiles' appeal, reducing animal suffering and euthanization.\n",
    "\n",
    "Top participants may be invited to collaborate on implementing their solutions into AI tools for assessing and improving pet adoption performance, which will benefit global animal welfare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective:\n",
    "you will predict the speed at which a pet is adopted, based on the pet’s listing on PetFinder. Sometimes a profile represents a group of pets. In this case, the speed of adoption is determined by the speed at which all of the pets are adopted. The data included text, tabular, and image data. See below for details. \n",
    "\n",
    "#### AdoptionSpeed\n",
    "\n",
    "Contestants are required to predict this value. The value is determined by how quickly, if at all, a pet is adopted. The values are determined in the following way: \n",
    "<br>0 - Pet was adopted on the same day as it was listed. \n",
    "<br>1 - Pet was adopted between 1 and 7 days (1st week) after being listed. \n",
    "<br>2 - Pet was adopted between 8 and 30 days (1st month) after being listed. \n",
    "<br>3 - Pet was adopted between 31 and 90 days (2nd & 3rd month) after being listed. \n",
    "<br>4 - No adoption after 100 days of being listed. (There are no pets in this dataset that waited between 90 and 100 days).\n",
    "\n",
    "\n",
    "\n",
    "__File descriptions:__\n",
    "<br>train.csv - Tabular/text data for the training set\n",
    "<br>test.csv - Tabular/text data for the test set\n",
    "<br>sample_submission.csv - A sample submission file in the correct format\n",
    "<br>breed_labels.csv - Contains Type, and BreedName for each BreedID. Type 1 is dog, 2 is cat.\n",
    "<br>color_labels.csv - Contains ColorName for each ColorID\n",
    "<br>state_labels.csv - Contains StateName for each StateID\n",
    "\n",
    "\n",
    "Data Fields\n",
    "\n",
    "- PetID - Unique hash ID of pet profile\n",
    "- AdoptionSpeed - Categorical speed of adoption. Lower is faster. This is the value to predict. See below section for more info.\n",
    "- Type - Type of animal (1 = Dog, 2 = Cat)\n",
    "- Name - Name of pet (Empty if not named)\n",
    "- Age - Age of pet when listed, in months\n",
    "- Breed1 - Primary breed of pet (Refer to BreedLabels dictionary)\n",
    "- Breed2 - Secondary breed of pet, if pet is of mixed breed (Refer to BreedLabels dictionary)\n",
    "- Gender - Gender of pet (1 = Male, 2 = Female, 3 = Mixed, if profile represents group of pets)\n",
    "- Color1 - Color 1 of pet (Refer to ColorLabels dictionary)\n",
    "- Color2 - Color 2 of pet (Refer to ColorLabels dictionary)\n",
    "- Color3 - Color 3 of pet (Refer to ColorLabels dictionary)\n",
    "- MaturitySize - Size at maturity (1 = Small, 2 = Medium, 3 = Large, 4 = Extra Large, 0 = Not Specified)\n",
    "- FurLength - Fur length (1 = Short, 2 = Medium, 3 = Long, 0 = Not Specified)\n",
    "- Vaccinated - Pet has been vaccinated (1 = Yes, 2 = No, 3 = Not Sure)\n",
    "- Dewormed - Pet has been dewormed (1 = Yes, 2 = No, 3 = Not Sure)\n",
    "- Sterilized - Pet has been spayed / neutered (1 = Yes, 2 = No, 3 = Not Sure)\n",
    "- Health - Health Condition (1 = Healthy, 2 = Minor Injury, 3 = Serious Injury, 0 = Not Specified)\n",
    "- Quantity - Number of pets represented in profile\n",
    "- Fee - Adoption fee (0 = Free)\n",
    "- State - State location in Malaysia (Refer to StateLabels dictionary)\n",
    "- RescuerID - Unique hash ID of rescuer\n",
    "- VideoAmt - Total uploaded videos for this pet\n",
    "- PhotoAmt - Total uploaded photos for this pet\n",
    "- Description - Profile write-up for this pet. The primary language used is English, with some in Malay or Chinese."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation:\n",
    "\n",
    "scored based on the quadratic weighted kappa, which measures the agreement between two ratings. This metric typically varies from 0 (random agreement between raters) to 1 (complete agreement between raters). In the event that there is less agreement between the raters than expected by chance, the metric may go below 0. The quadratic weighted kappa is calculated between the scores which are expected/known and the predicted scores.\n",
    "\n",
    "Results have 5 possible ratings, 0,1,2,3,4.  The quadratic weighted kappa is calculated as follows. First, an N x N histogram matrix O is constructed, such that Oi,j corresponds to the number of adoption records that have a rating of i (actual) and received a predicted rating j. An N-by-N matrix of weights, w, is calculated based on the difference between actual and predicted rating scores:\n",
    "\n",
    "$$\\begin{equation*}\n",
    "w_{ij} = \\frac{(i-j)^2}{(N-1)^2}\n",
    "\\end{equation*} $$\n",
    "\n",
    "\n",
    "An N-by-N histogram matrix of expected ratings, E, is calculated, assuming that there is no correlation between rating scores.  This is calculated as the outer product between the actual rating's histogram vector of ratings and the predicted rating's histogram vector of ratings, normalized such that E and O have the same sum.\n",
    "\n",
    "From these three matrices, the quadratic weighted kappa is calculated as: \n",
    "\n",
    "$$\\begin{equation*}\n",
    "\\kappa = 1 - \\frac{\\sum_(w_{ij} O_{ij})}{\\sum_(w_{ij} E_{ij})}\n",
    "\\end{equation*} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayeshamendoza/anaconda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, json\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier as ET\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, cohen_kappa_score\n",
    "\n",
    "# Metric used for this competition (Quadratic Weigthed Kappa aka Quadratic Cohen Kappa Score)\n",
    "def metric(y1,y2):\n",
    "    return cohen_kappa_score(y1,y2, weights='quadratic')\n",
    "\n",
    "# Make scorer for scikit-learn\n",
    "scorer = make_scorer(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features to add from train dataset\n",
    "- number of colors\n",
    "- pure bred or mixed breed\n",
    "- Description length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color_cols = ['Color1', 'Color2', 'Color3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_breed(row):\n",
    "    \"\"\" this function sets the Mixed Breed Indicator for the pet\n",
    "        a dog is set as Mixed Breed if either Breed1 or Breed2 = 370\n",
    "        or both Breed1 and Breed2 is set to some value greater than 0.\n",
    "        A cat is set as Mixed Breed if either Breed1 or Breed2 = 266\n",
    "        or both Breed1 and Breed2 is set to some value greater than 0.\n",
    "    \"\"\"\n",
    "    if (row['Type'] == 'Dog'): \n",
    "        if (((row['Breed1'] == 370) | (row['Breed2'] == 370)) |\n",
    "            ((row['Breed1'] > 0) & (row['Breed2'] > 0))):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else: # if 'Cat'\n",
    "        if (((row['Breed1'] == 266) | (row['Breed2'] == 266)) |\n",
    "            ((row['Breed1'] > 0) & (row['Breed2'] > 0))):\n",
    "            return 1 #mixed\n",
    "        else:\n",
    "            return 0 #Pure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_desc_len(row):\n",
    "    \"\"\" return length of Pet's profile Description\"\"\"\n",
    "    return len(row['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_name_len(row):\n",
    "    \"\"\" return length of Pet's Name\"\"\"\n",
    "    return len(row['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_color_count(row):\n",
    "    \"\"\" return the number of colors of the pet\"\"\"\n",
    "    color_count = 0\n",
    "    \n",
    "    for color in color_cols:\n",
    "        if row[color] > 0:\n",
    "            color_count +=1\n",
    "            \n",
    "    return color_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_age_cat(row):\n",
    "    \"\"\" return the age category for dogs and cats \"\"\"\n",
    "    if row['Type'] == 'Dog':\n",
    "        if (row['Age'] >= 0) & (row['Age'] < 24):\n",
    "            return 'dog_0_23'\n",
    "        elif (row['Age'] >= 24) & (row['Age'] < 72):\n",
    "            return 'dog_24_71'\n",
    "        elif (row['Age'] >= 72) & (row['Age'] < 120):\n",
    "            return 'dog_72_119'\n",
    "        elif row['Age'] >= 120:\n",
    "            return 'dog_120_above'\n",
    "    else:\n",
    "        if (row['Age'] >= 0) & (row['Age'] < 2):\n",
    "            return 'cat_0_1'\n",
    "        elif (row['Age'] >= 2) & (row['Age'] < 6):\n",
    "            return 'cat_2_5'\n",
    "        elif (row['Age'] >= 6) & (row['Age'] < 12):\n",
    "            return 'cat_6_11'\n",
    "        elif row['Age'] >= 12:\n",
    "            return 'cat_12_above'        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_sentiment(filetype):\n",
    "    \"\"\" This function processes the description sentiment file and creates a sentiment score dataframe.\n",
    "        the filetype (train or test) will be a required parameter\"\"\"\n",
    "    \n",
    "    path_to_json = '../data/{}_sentiment/'.format(filetype)\n",
    "    json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "    json_dict = {'pet_id':[],'magnitude':[], 'score':[]}\n",
    "\n",
    "    for index, js in enumerate(json_files):\n",
    "     \n",
    "        with open(os.path.join(path_to_json, js)) as json_file:\n",
    "            json_text = json.load(json_file)\n",
    "            json_dict['pet_id'].append(js.split('.')[0])\n",
    "            json_dict['magnitude'].append(json_text['documentSentiment']['magnitude'])\n",
    "            json_dict['score'].append(json_text['documentSentiment']['score'])\n",
    "            \n",
    "    sentiDF = pd.DataFrame(json_dict)\n",
    "    return sentiDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_features(df, filetype):\n",
    "    \"\"\" This function adds new features to our dataFrame as part of pre-processing\n",
    "        of train and test data.  The parameter filetype will either be (train or test)\"\"\"\n",
    "    \n",
    "    dfAdd = df.copy()\n",
    "\n",
    "    #Handle Missing Values\n",
    "    dfAdd['Name'] = dfAdd.Name.fillna('').values\n",
    "    dfAdd['Description'] = dfAdd.Name.fillna('').values\n",
    "    \n",
    "    \n",
    "    #Add Features\n",
    "    dfAdd['Name_Ind'] = dfAdd['Name'].apply(lambda x: 1 if len(x) > 0 else 0)\n",
    "    dfAdd['Name_Len'] = dfAdd.apply(lambda x: get_name_len(x), 1)\n",
    "    dfAdd['Breed_Ind'] = dfAdd.apply(lambda x: set_breed(x), 1)\n",
    "    dfAdd['Desc_Len'] = dfAdd.apply(lambda x: get_desc_len(x), 1)\n",
    "    dfAdd['Color_count'] = dfAdd.apply(lambda x: get_color_count(x), 1)\n",
    "    dfAdd['age_cat'] = dfAdd.apply(lambda x:get_age_cat(x), 1)  \n",
    "  \n",
    "    #Get descriptions for the different numeric categorical features\n",
    "    colors_dict = {k: v for k, v in zip(color['ColorID'], color['ColorName'])}\n",
    "    dfAdd['Color1_name'] = dfAdd['Color1'].apply(lambda x: '_'.join(colors_dict[x].split()) if x in colors_dict else 'Unknown')\n",
    "    dfAdd['Color2_name'] = dfAdd['Color2'].apply(lambda x: '_'.join(colors_dict[x]) if x in colors_dict else '-')\n",
    "    dfAdd['Color3_name'] = dfAdd['Color3'].apply(lambda x: '_'.join(colors_dict[x]) if x in colors_dict else '-')\n",
    "    \n",
    "    breeds_dict = {k: v for k, v in zip(breed['BreedID'], breed['BreedName'])}\n",
    "    dfAdd['Breed1_name'] = dfAdd['Breed1'].apply(lambda x: '_'.join(breeds_dict[x].split()) if x in breeds_dict else 'Unknown')\n",
    "    dfAdd['Breed2_name'] = dfAdd['Breed2'].apply(lambda x: '_'.join(breeds_dict[x]) if x in breeds_dict else '-')\n",
    "    \n",
    "    \n",
    "    #After all the new columns have been added to the dataframe.  Join dfAll with desc_df to populate\n",
    "    #the dataframe with the description sentiment score\n",
    "    desc_df = process_sentiment(filetype)\n",
    "    desc_df.rename(index=str, columns={'pet_id': 'PetID'}, inplace=True)\n",
    "    dfAdd = dfAdd.merge(desc_df, on=['PetID'], how='left')\n",
    "    dfAdd.fillna(0, inplace=True)\n",
    "    \n",
    "    dfAdd['sentiment'] = dfAdd.apply(lambda x: x['magnitude'] * x['score'], 1)\n",
    "    \n",
    "    return dfAdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load files\n",
    "\n",
    "breed = pd.read_csv('../input/breed_labels.csv')\n",
    "color = pd.read_csv('../input/color_labels.csv')\n",
    "state = pd.read_csv('../input/state_labels.csv')\n",
    "\n",
    "train = pd.read_csv('../input/train/train.csv')\n",
    "\n",
    "test = pd.read_csv('../input/test/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_num_cols = ['Type','Gender','sentiment', 'score', 'Color_count', 'Desc_Len', 'Name_Len', \n",
    "                 'PhotoAmt', 'Quantity', 'Age', 'MaturitySize', 'FurLength',\n",
    "                 'Sterilized','Dewormed', 'Vaccinated','Health','Fee','State', 'Name_Ind',\n",
    "                 'Breed_Ind','Color1', 'Color2', 'Color3','Breed1', 'Breed2',]\n",
    "corr_cat_cols = ['age_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create a class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(corr_num_cols)),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process Train file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfAll = add_features(train, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xnum = num_pipeline.fit_transform(dfAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayeshamendoza/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "petFinder_cat = dfAll[corr_cat_cols]\n",
    "PF_cat_encoded, PF_categories = petFinder_cat['age_cat'].factorize()\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(PF_cat_encoded.reshape(-1,1))\n",
    "cat_scaled = sc.transform(PF_cat_encoded.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfnew = pd.DataFrame(np.c_[Xnum, cat_scaled], columns=corr_num_cols + corr_cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 26) (14993,)\n"
     ]
    }
   ],
   "source": [
    "X  = dfnew.as_matrix()\n",
    "y = dfAll['AdoptionSpeed'].values\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Process Test File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTest = add_features(test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3948, 25)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Test_X = num_pipeline.fit_transform(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayeshamendoza/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "PF_cat = dfTest[corr_cat_cols]\n",
    "PF_cat_encoded, PF_categories = PF_cat['age_cat'].factorize()\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(PF_cat_encoded.reshape(-1,1))\n",
    "cat_scaled = sc.transform(PF_cat_encoded.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-daedaa2bd1e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_scaled\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorr_num_cols\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcorr_cat_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mTest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "Test_df = pd.DataFrame(np.c_[Test_X, cat_scaled], columns=corr_num_cols + corr_cat_cols)\n",
    "Test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c9907eacdb22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTest_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Test_df' is not defined"
     ]
    }
   ],
   "source": [
    "Test_X = Test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3948, 26)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14993, 425)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Predict Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier (kernel='poly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=5, cache_size=200, class_weight=None, coef0=1,\n",
       "  decision_function_shape=None, degree=10, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_kernel_svm_clf = SVC(kernel=\"poly\", degree=10, coef0=1, C=5)\n",
    "poly_kernel_svm_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32147621164962203\n",
      "0.17943174936913753\n"
     ]
    }
   ],
   "source": [
    "y_pred = poly_kernel_svm_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(metric(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Classifier with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41329479768786126\n",
      "0.3665934991490325\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest Classifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=3, criterion='entropy')\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(metric(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(rf, random_state=42, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=3, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=100, n_jobs=1, oob_score=False,\n",
       "         random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4266340595820365 0.37426304220949824\n"
     ]
    }
   ],
   "source": [
    "y_bag_pred = bag_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_bag_pred)\n",
    "score = metric(y_test, y_bag_pred)\n",
    "print(accuracy, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting \n",
    "[hyperparameter tuning](https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbt_clf = GradientBoostingClassifier(n_estimators=300, max_depth=1, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=1,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=300, presort='auto', random_state=42,\n",
       "              subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3325686769219627\n"
     ]
    }
   ],
   "source": [
    "y_pred = gbt_clf.predict(X_test)\n",
    "score = metric(y_test, y_pred)\n",
    "print(score)  # original score: 0.29297979606827806"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgbt_clf = GradientBoostingClassifier(n_estimators=300, max_depth=1, \n",
    "                                      subsample=0.8,\n",
    "                                      max_features=0.7,\n",
    "                                      random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgbt_clf.fit(X_train, y_train)\n",
    "y_pred = sgbt_clf.predict(X_test)\n",
    "score = metric(y_test, y_pred)\n",
    "print(score) #original score: 0.30550830837124776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_list = {\n",
    "              'n_estimators': [300,400,500],\n",
    "              'max_depth': [4, 6, 8],\n",
    "              'min_samples_split': [50, 100, 120],\n",
    "              'min_samples_leaf': [5, 10, 15],\n",
    "              'learning_rate': [0.1, 0.3, 0.5]\n",
    "            \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_gbt = GridSearchCV(estimator=gbt_clf, param_grid=param_list, cv=3,\n",
    "                       scoring='accuracy',verbose=1,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_gbt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_gbt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_gs_pred = grid_gbt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_gs_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = metric(y_test, y_gs_pred)\n",
    "print(score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgbt_clf2 = GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
    "              learning_rate=0.1, loss='deviance', max_depth=2,\n",
    "              max_features=None, max_leaf_nodes=None,\n",
    "              min_impurity_split=1e-07, min_samples_leaf=3,\n",
    "              min_samples_split=100, min_weight_fraction_leaf=0.0,\n",
    "              n_estimators=200, presort='auto', random_state=42,\n",
    "              subsample=1.0, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41751889728768343 0.3915879000654472\n"
     ]
    }
   ],
   "source": [
    "sgbt_clf2.fit(X_train, y_train)\n",
    "y_sgbt2_pred = sgbt_clf2.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_sgbt2_pred)\n",
    "score = metric(y_test, y_sgbt2_pred)\n",
    "print(accuracy, score) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Prepare Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "petid = list(dfTest.PetID.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3948"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(petid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Test_Pred = sgbt_clf2.predict(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({'PetID': petid, 'AdoptionSpeed': list(Test_Pred)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PetID</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>378fcc4fc</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73c10e136</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72000c4c5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e147a4b9f</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43fbba852</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PetID  AdoptionSpeed\n",
       "0  378fcc4fc              2\n",
       "1  73c10e136              4\n",
       "2  72000c4c5              4\n",
       "3  e147a4b9f              4\n",
       "4  43fbba852              4"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = sub_df[['PetID', 'AdoptionSpeed']]\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
